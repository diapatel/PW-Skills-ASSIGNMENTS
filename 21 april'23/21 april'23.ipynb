{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac510e2-9276-4ca6-9c5e-89615689ad63",
   "metadata": {},
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?<br>\n",
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?<Br>\n",
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "what situations might you choose one distance metric over the other?<Br>\n",
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?<Br>\n",
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "techniques can be used to optimize the size of the training set?<Br>\n",
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c0d91-c973-4a62-8669-943ec00a04f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d49eee5a-18b1-408d-9678-5807e193b279",
   "metadata": {},
   "source": [
    "### SOLUTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f83595-88fb-4963-bcd6-74144c1eaff9",
   "metadata": {},
   "source": [
    "* Minkowski is a metric which has a power parameter p. this decides what vector norm we are calculating.\n",
    "* when p=1,we are calculating L1 norm which is equivalent to Manhattan distance\n",
    "* In manhattan distance, we calculate the absolute value of  the distance between 2 vectors, whereas in Euclidean distance, we calculate the square of the distance between 2 points/vectors.\n",
    "* When p=2,we are calculating L2 norm which is equivalent to Euclidean distance.\n",
    "* Usually as the dimensions of the data increases, it has been observed that lower values of p work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a096eb8-940a-4429-9737-31f324a04590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dba762a-c72d-4bd4-9e83-017ee0d17957",
   "metadata": {},
   "source": [
    "### SOLUTION 2\n",
    "\n",
    "* HEURISTIC APPROACH: in this, k= square root of number of rows.\n",
    "* CROSS VALIDATION APPROACH: in this, we train different KNN models with different k values and then choose the one with the maximum accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b907ca-4e28-48f9-ba40-9d892c853b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "084b0ca0-bebf-4594-b0ad-942491ada214",
   "metadata": {},
   "source": [
    "### SOLUTION 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b86af-0590-4b7f-8399-08cf6151c815",
   "metadata": {},
   "source": [
    "* the choice of the distance metric affects the model performance.\n",
    "* It has been experimentally observed that as the number of dimensions increases, lower values of p(power parameter for Minkowski distance) have shown better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d04f0-9506-4e1d-b677-62f74dc25f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c813273e-b711-4fb2-b13b-dea37c97b729",
   "metadata": {},
   "source": [
    "### SOLUTION 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed6a3d-a074-4f62-8542-817167e96154",
   "metadata": {},
   "source": [
    "* n_neighbors: number of neighbors to be considered\n",
    "\n",
    "* weights: it can be uniform or distance. if it is set to uniform, each neighbor is considered to have equal importance whereas if it is set to distance, the neighbor that is closer is considered to have more impact or given more weight as compared to the one that is farther.  it can be used to penalize outliers.\n",
    "\n",
    "* p : power parameter for minkowski metric. decides what kind of distance between 2 points will be calculated.\n",
    "\n",
    "* n_jobs: number of parallel jobs being performed to search for neighbors. by default it is 1 where only 1 processor is used whereas -1 means all the available processors will be used. if my machine has quad core processor, then i'll get the output 4 times faster\n",
    "\n",
    "* metric: by default it is minkowski. it determines what kind of distance is to be used\n",
    "\n",
    "* algorithm: it can be auto, brute, kdtree or ball tree. it decides what kind of algorithm will be used.\n",
    "\n",
    "* leaf: it is to be used in case of kdtree and ball tree algorithms. it determines the speed of construction and query and how much space will be required to store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d48b1-b71e-43cc-8407-79bc529f616e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b69dac8c-a8f2-4fa3-a746-9bf138315abd",
   "metadata": {},
   "source": [
    "### SOLUTION 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcddd29-a790-469b-bbe0-b83a574c599c",
   "metadata": {},
   "source": [
    "* In KNN, the training data is stored in the RAM. so ,larger the data , more the space required for storage. \n",
    "* to handle this, we can algorithms like KDtree where we construct a tree based on the coordinates of the training points and minimize the number of distances to be calculated. this improves the time complexity but doesn't improve the space complexity because all of the training data still needs to be stored. \n",
    "* we can reduce the number of dimensions using dimensionality reduction algorithms like PCA to reduce the space and time complexity both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03077d1-a706-4ec4-a7d1-1cd210f87541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e609d80f-9691-4b40-9871-94c2ce802608",
   "metadata": {},
   "source": [
    "### SOLUTION 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacb5e8-8263-4a0b-9c2c-8953f10d7214",
   "metadata": {},
   "source": [
    "* KNN is very slow so it shouldn't be used for huge datasets or datasets with high dimensionality. we can reduce the number of dimensions by using PCA and other such algorithms and also use algorithms like KD tree to improve time complexity. but still, storage space required is too large.\n",
    "\n",
    "* KNN should be avoided in scenarios where inference is more valuable than prediction because KNN works as a black box model .\n",
    "\n",
    "* It should be assured that dataset is balanced before applying KNN on it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02349299-bec0-4f67-b4e1-b157d0f29009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb35922-f47b-4c5c-94d4-3a739a1c8613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
