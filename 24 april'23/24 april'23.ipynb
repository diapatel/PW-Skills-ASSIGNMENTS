{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74331aea-452c-45d2-8e53-926f0bd19a39",
   "metadata": {},
   "source": [
    "Q1. What is a projection and how is it used in PCA?<Br>\n",
    "Q2. How does the optimization problem in PCA work, and what is it trying to achieve?<Br>\n",
    "Q3. What is the relationship between covariance matrices and PCA?<Br>\n",
    "Q4. How does the choice of number of principal components impact the performance of PCA?<Br>\n",
    "Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?<Br>\n",
    "Q6. What are some common applications of PCA in data science and machine learning?<Br>\n",
    "Q7.What is the relationship between spread and variance in PCA?<Br>\n",
    "Q8. How does PCA use the spread and variance of the data to identify principal components?<Br>\n",
    "Q9. How does PCA handle data with high variance in some dimensions but low variance in others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7017321-8f26-41fc-94da-e02aaea91494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b450e85c-4451-4f9f-9b68-d0f994028b10",
   "metadata": {},
   "source": [
    "### SOLUTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8455bf1-9284-443b-abc7-8e36fab8c721",
   "metadata": {},
   "source": [
    "* the projection of one vector over another is the length of the shadow of the given vector over another vector. it is a scalar value\n",
    "* the data values of predictors are vectors and they are projected on a unit vector and then the variance is calcualted. the unit vector that shows maximum variance is selected to be the principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07b31f-4537-40c4-a3ee-19125338ff21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "574e0eca-3e1a-43f4-8005-c27683aa4c7f",
   "metadata": {},
   "source": [
    "### SOLUTION 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f29c5c-6c84-46d0-ba1a-c3ac78c14549",
   "metadata": {},
   "source": [
    "* In PCA, we project the vectors of all data points on a unit vector and then calculate the variance. we do this for all possible unit vectors until we find a unit vector where the variance is maximum.\n",
    "* the unit vector which shows the maximum variance is then selected to be the principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e1776-bad4-4125-bac1-58b1b56e0519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a277b2fc-81ff-4125-b8c6-e5b67ec0b5f3",
   "metadata": {},
   "source": [
    "### SOLUTION 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701567a-2235-4b5a-823a-b27afd90e32a",
   "metadata": {},
   "source": [
    "* PCA tries to find a unit vector for which the variance is maximum.\n",
    "* covariance matrix is a matrix that has variances of all the possible combinations for a given number of predictors.\n",
    "* the diagonal elements of the covariance matrix show the variance for each variable.\n",
    "* eigen vectors are determined for the covariance matrix  and the eigen vector with the maximum eigen value has the maximum variance and is thus selected as the principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc3e34-d4f0-453d-8201-05068a159954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66ad5a1d-1eb8-4014-b758-d4f339c8f5ac",
   "metadata": {},
   "source": [
    "### SOLUTION 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b4a09-a579-42be-86db-9a929e536322",
   "metadata": {},
   "source": [
    "* When the number of components is low, the value of explained variance is low and so the performance of PCA is not very accurate bus as the number of components increases, the value of explained variance increases upto a certain extent, after which it increases very slightly. \n",
    "* when we plot the number of components against explained variance, we look for the value of number of components where the graph reaches its peak and that is the optimum number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a10aa7-54fb-4a1e-bb8c-2ee977a5f5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "face7dcd-998e-4c76-9454-59efdd1ee1ed",
   "metadata": {},
   "source": [
    "### SOLUTION 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d2530-2784-45cc-be82-fea00aa8094a",
   "metadata": {},
   "source": [
    "* PCA extracts the most important features of a dataset and helps in reducing the dimensionality of the dataset. so , it helps in feature extraction.\n",
    "\n",
    "* BENEFITS : \n",
    "\n",
    "1. helps in reducing dimensionality\n",
    "2. helps in visualising higher dimension data in 3-D or 2-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452601d-96b4-48a6-b1a4-715cf991a9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2618a6d5-a917-496f-9ddb-8d1e2b5c55f8",
   "metadata": {},
   "source": [
    "### SOLUTION 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f52be-ed20-453b-b8b1-69a47dafbbf0",
   "metadata": {},
   "source": [
    "* DIMENSIONALITY REDUCTION: it helps in bringing higher dimensional data down to lower dimensions.\n",
    "* VISUALISATION: Higher dimensional data can be reduced to 2-D or 3-D data so that it can be easily visualised.\n",
    "* FEATURE EXTRACTION: it helps in extracting new features from the existing set of features which are linear combinations of the original features, and are selected based on the extent to which they explain the variability in the data. it helps in identifying latent factors or patterns.\n",
    "* ENHANCING SIGNAL-TO-NOISE RATIO: PCA reduces noise in the data by extracting features that explain a significant proprotion of variation in the data. \n",
    "* ML Preprocessing : used to reduce multicollinearity, computational complexity, and enhancing the performance of the model by eliminating irrelevant or redundant features.\n",
    "* ANOMALY DETECION: by reprsenting normal variation in the data using the principal components, instances that deviate significantly from this variation can be idenitified and these are anomalies or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c5d8c-6fd6-4924-ab63-a04a3e265b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3045589-274c-413e-8cf4-625b1d95266b",
   "metadata": {},
   "source": [
    "### SOLUTION 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03abd0-61ea-4ac1-a12d-6a02b2ccf1fb",
   "metadata": {},
   "source": [
    "* Variance is a statistical measure which measures the square of average distance of a data point from the mean.\n",
    "* Variance is a measure of spread or variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41baa7-2c16-4b40-b117-27c1d6b9baa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "624eb916-7b2e-4229-8b9b-d58d39c7f730",
   "metadata": {},
   "source": [
    "### SOLUTION 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ffa186-8d5b-47cc-99d9-bdb50ee9449b",
   "metadata": {},
   "source": [
    "* PCA tries to find the value of a unit vector on which when the vectors of data points are projected, we get maximum variance. \n",
    "* we use variance and most importantly , covariance matrix because it tells us how variables vary with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6cbafa-1464-453d-afc1-be6a11059396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0282147c-2fa2-4c10-bc79-14c3cfdb06a9",
   "metadata": {},
   "source": [
    "### SOLUTION 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd041f-afee-4a97-90a0-8cccb0567a52",
   "metadata": {},
   "source": [
    "* PCA is a dimensionality reduction algorithm used to transform high dimensionality data into lower dimensions while retaining the original patterns and relationships in the data.\n",
    "* It tries to find the dimensions along which the data varies the most.\n",
    "* in a dataset, some dimensions will have higher variance and other will have lower variance. PCA emphasises on dimensions with higher variance.\n",
    "* the principal components capture the direction of the maximum variance of the data, with the first principal component having the largest value of variance, second principal component having the second largest value of variance and so on.\n",
    "* PCA calculates the covariance matrix of the input data which displays the relationship between the dimensions in the dataset. the dimensions that have the high variance will contribute more to the overall variability in the data whereas the dimensions with lower variance would contribute lesser to the overall variability in the data.\n",
    "* the principal components are identified by determining the longest eigen vectors, ie the eigen vectors with the highest eigen values because these will be the components with high variance and thus will highly contribute to the variability in the data. these components are given more importance as compared to the eigen vectors with lower eigen values and thus not-so-significant contribution to the variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56034ca2-f215-4955-a4cf-39ab01300789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
