{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0f4a76-5024-493c-80dd-8f2e6a367f50",
   "metadata": {},
   "source": [
    "<b>QUESTION 1: </b>Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?<Br>\n",
    "<b>SOLUTION: </b>\n",
    "* R-squared is a statistical measure used to measure the goodness of fit.\n",
    "* It is calculated by subtracting the ratio of residul sum of squares with the total sum of squares from 1.\n",
    "* the residual sum of squares is calculated by summation of the square of difference between data points and line of best fit\n",
    "* The total sum of squares is calculated by summation of square of difference between data points and the average line.\n",
    "* Closer the value of R-squared is to 1, better is the fit of the model\n",
    "* the ideal value if R2 score is 1.\n",
    "    \n",
    "    \n",
    "* LIMITATION OF R2 SCORE:\n",
    "If a column that is irrelevant to the target variable is added to the dataset, the R-squared score should decrease, but it either remains the same or increases. This is because SStotal is always constant so, the model tries to decrease the value of SSRes by finding some sort of correlation with the newly added variable which in turn increases the value of R-squared score."
   ]
  },
  {
   "attachments": {
    "d8c572d7-ea58-4214-9927-73140679f113.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHUAAAAnCAYAAAAxQgdAAAAFh0lEQVR4nO2bQXLaWBCG/37CyVbxINiZF+UGODnB4B2FVC47OUHsG0DlBCm4gZ0TTDk1BS7v4AaJuQEaMTsb4rB20OtZCGEh8ASMjCmjb2Nbr59K0Hqvu//XJiTEQjpXzBO0TyAUAOjMaAliBwCYaRsAGN7nfveifd98QeJYAQMAEBA/rt16LSNLJ9fu+fGidgkxkpF22ZAWZ3f2zfD1rGkVDGlxRtrl6Jx0rphP56xm+Joubd2Q9qUh7ctF7UR8HycBAIIVFOXKabSY0WJwNepwotQXTUM1fG3g1gfMw48PsUucukKC7Rgpz5wcYZMV5aP2/e5FGzyas4Bd4tQVwhBvAXaunEZrcoQcBn+KrmAAEKxVFrVLxfnQCbPJ7uybirwqM98MSfwZHWcefiTSLpXwOoa02wzV0gQ1r5xG6+rfv51F7WhVH2xTSEv7iMAnDK4BoiMAnYEPYHZ63cbhvfNyxTygVcnPnkewI1RqL+yweewSp8ZM4FShtDeTzrCaRGz23PM3v71HrpgHiQ8EKgPU7rn13UXslo6p6Vwxn5F2OSPtspGzzrKmVfj9rM3Dz1rJTEv7KDoWjZH97kW7755XQDgEOB+Mz2u3tFMFpQrXbr127dZrgrWKUmjOCuSbjud5N/5vamqlshhWotcAoPdP4ysAeHSrL2K3lFPTuWKewVVd2joA+NsNOyzUwTL3fY5o/MKvX/muJAm+Nwb+d3cbUspZxG4pp/a7F20QDgdufaLgvq8A3wQE1C4AKM2bqCeDFz6c4KSA9/5vZBo56yy6w6Vlqcrg2t33O59drIlSdmffVMLr/AK9ijr6uRNosoD/UgtAB4CwHpvd2Tc98k58EUJ0boHTgVsfGDnrrNdtHKZlqQoAwVwFcdl366fB/HntJpyqS1t/AVX1lzmZgSh9J0hDB7zKfaK0Ie1LIbgyXVyvjrQsVQOR+6me4amZuVIzsnTCoPc9t/EqfN14bR2AcSYE9qKOy8jSCRM1g6C9SsKrhEFHBKpsslNnYshSx8hZZ7PHLI6eFBivrQPjtTVOjp6yrDGk9XPWScgmMSUT+hkZm0xUjY75agYA4vH2mzWtAisyb4FTXdr6S8FvFft7fcLTMOXULeICGNCUmBEXtSrAzhDiM+C/AEpxE2BswT8SUgpg9mYqIAmrYcqpxLzHoEEgcY1Xn4djInZuIcYlzOhnIjWuGVNOHWW+zp2cpd4ohQOh0fGVcx5LVpuRpRPFtIDqdH/GnTDNhFOzO/umgmcycByue7Km1RzJfxMi9UN5jr00hrT4qZ8hYMKpnlAFwox4OtQcCA+eUAUAp3gGBEdY89gKYud3L2LPbaxNGJpwKjHvgTCIrkaleXkwQMQ3q328x2O0ne899XM8BpMxlVAAYypuMvM7AkGQr+nq0taXkQGTmPq4jJ2aNa2CUtCJ6FvUSED8YPD4+OgFcATgwYrNI8dUXUH98Yj3X3so0HuB+4VoXdr6FvMXf/sVHVLiaxwJU1xkd/ZNFsOKYjJHpyADMFpE9G0T5cK1Ce7PAUOWOgAApjYR3zDTNojzgBgQ1Hdm2mZAJ2KTIarhCiPODv2kmzAmfHlV4RfE7qBbH+ceW8BPhqr13PNx10JG2mUOdUAEmfi129gL38+Q9mW4TprXLun7jYmXSmwzRHWeBPLardeCMAckHfrrS8ozwcPv85pPdockHfrryVBzFiq7WP1190e8HfpJovSI+DGVfzK41g/F1CjpXDFPpI3+a40mOu8fYpes1DWg371oM3u7zGgBnCdQWSk0DVnqhFflvHZJ9rsmhGXLcOe9EuoMwO4idslKXQPWrkM/YXnWqkM/IR7WqkM/IS7WuEM/wScj7TIzvwORCXAe4wMGviGVqkYPQ+Lu0P8PYdmjkABI9vAAAAAASUVORK5CYII="
    },
    "e35d4b1c-65b2-44b6-b8b2-c89b203b7930.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHUAAAAnCAYAAAAxQgdAAAAFh0lEQVR4nO2bQXLaWBCG/37CyVbxINiZF+UGODnB4B2FVC47OUHsG0DlBCm4gZ0TTDk1BS7v4AaJuQEaMTsb4rB20OtZCGEh8ASMjCmjb2Nbr59K0Hqvu//XJiTEQjpXzBO0TyAUAOjMaAliBwCYaRsAGN7nfveifd98QeJYAQMAEBA/rt16LSNLJ9fu+fGidgkxkpF22ZAWZ3f2zfD1rGkVDGlxRtrl6Jx0rphP56xm+Joubd2Q9qUh7ctF7UR8HycBAIIVFOXKabSY0WJwNepwotQXTUM1fG3g1gfMw48PsUucukKC7Rgpz5wcYZMV5aP2/e5FGzyas4Bd4tQVwhBvAXaunEZrcoQcBn+KrmAAEKxVFrVLxfnQCbPJ7uybirwqM98MSfwZHWcefiTSLpXwOoa02wzV0gQ1r5xG6+rfv51F7WhVH2xTSEv7iMAnDK4BoiMAnYEPYHZ63cbhvfNyxTygVcnPnkewI1RqL+yweewSp8ZM4FShtDeTzrCaRGz23PM3v71HrpgHiQ8EKgPU7rn13UXslo6p6Vwxn5F2OSPtspGzzrKmVfj9rM3Dz1rJTEv7KDoWjZH97kW7755XQDgEOB+Mz2u3tFMFpQrXbr127dZrgrWKUmjOCuSbjud5N/5vamqlshhWotcAoPdP4ysAeHSrL2K3lFPTuWKewVVd2joA+NsNOyzUwTL3fY5o/MKvX/muJAm+Nwb+d3cbUspZxG4pp/a7F20QDgdufaLgvq8A3wQE1C4AKM2bqCeDFz6c4KSA9/5vZBo56yy6w6Vlqcrg2t33O59drIlSdmffVMLr/AK9ijr6uRNosoD/UgtAB4CwHpvd2Tc98k58EUJ0boHTgVsfGDnrrNdtHKZlqQoAwVwFcdl366fB/HntJpyqS1t/AVX1lzmZgSh9J0hDB7zKfaK0Ie1LIbgyXVyvjrQsVQOR+6me4amZuVIzsnTCoPc9t/EqfN14bR2AcSYE9qKOy8jSCRM1g6C9SsKrhEFHBKpsslNnYshSx8hZZ7PHLI6eFBivrQPjtTVOjp6yrDGk9XPWScgmMSUT+hkZm0xUjY75agYA4vH2mzWtAisyb4FTXdr6S8FvFft7fcLTMOXULeICGNCUmBEXtSrAzhDiM+C/AEpxE2BswT8SUgpg9mYqIAmrYcqpxLzHoEEgcY1Xn4djInZuIcYlzOhnIjWuGVNOHWW+zp2cpd4ohQOh0fGVcx5LVpuRpRPFtIDqdH/GnTDNhFOzO/umgmcycByue7Km1RzJfxMi9UN5jr00hrT4qZ8hYMKpnlAFwox4OtQcCA+eUAUAp3gGBEdY89gKYud3L2LPbaxNGJpwKjHvgTCIrkaleXkwQMQ3q328x2O0ne899XM8BpMxlVAAYypuMvM7AkGQr+nq0taXkQGTmPq4jJ2aNa2CUtCJ6FvUSED8YPD4+OgFcATgwYrNI8dUXUH98Yj3X3so0HuB+4VoXdr6FvMXf/sVHVLiaxwJU1xkd/ZNFsOKYjJHpyADMFpE9G0T5cK1Ce7PAUOWOgAApjYR3zDTNojzgBgQ1Hdm2mZAJ2KTIarhCiPODv2kmzAmfHlV4RfE7qBbH+ceW8BPhqr13PNx10JG2mUOdUAEmfi129gL38+Q9mW4TprXLun7jYmXSmwzRHWeBPLardeCMAckHfrrS8ozwcPv85pPdockHfrryVBzFiq7WP1190e8HfpJovSI+DGVfzK41g/F1CjpXDFPpI3+a40mOu8fYpes1DWg371oM3u7zGgBnCdQWSk0DVnqhFflvHZJ9rsmhGXLcOe9EuoMwO4idslKXQPWrkM/YXnWqkM/IR7WqkM/IS7WuEM/wScj7TIzvwORCXAe4wMGviGVqkYPQ+Lu0P8PYdmjkABI9vAAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "4c026855-59b2-441a-9599-409f1ccfbeb1",
   "metadata": {},
   "source": [
    "![image.png](attachment:e35d4b1c-65b2-44b6-b8b2-c89b203b7930.png)![image.png](attachment:d8c572d7-ea58-4214-9927-73140679f113.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adf8fe-c21a-45bf-a222-7099843a1378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e69a8d-9907-4ab0-950c-8cc1a3b95c56",
   "metadata": {},
   "source": [
    "<b>QUESTION 2: </b> Define adjusted R-squared and explain how it differs from the regular R-squared.<Br>\n",
    "<b>SOLUTION: </b>\n",
    "* when some irrelevant column is added to the data, R-squared should ideally decrease but it either remains constant or decreases.\n",
    "* to tackle this, we have adjusted R-squared.\n",
    "* adjusted R-squared = ((1-r2)(n-1))/(n-1-k)<br><Br>\n",
    "    where r2 = R-squared error<br>\n",
    "    n = no. of rows<br>\n",
    "    k = no. of independent variables<br>\n",
    "    \n",
    "    \n",
    "* when an irrelevant feature is added to the data, adjusted R-squared decreases and when a relevant feature is added, it increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d6810-3ce8-4522-9ce1-9aa686799c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac5360-2422-4200-bd47-44304fad5f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "472de6a8-627f-4381-ab2f-03ad7904f360",
   "metadata": {},
   "source": [
    "<b>QUESTION 3: </b>When is it more appropriate to use adjusted R-squared?<Br>\n",
    "<b>SOLUTION: </b>\n",
    "* It is more appropriate to use adjusted R-squared because it behaves appropriately whenever we add new variables to the dataset.\n",
    "* if some irrelevant variable is added, it decreases and if some relevant variable is added, it increases.\n",
    "* on the other hand, R-squared doesn't reflect any such changes and hence , is not reliable.<Br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927f3c6-e732-4c53-8b44-5c4c98340eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad6dc89e-8ac0-4999-8393-1e36986f03bf",
   "metadata": {},
   "source": [
    "<b>QUESTION 4: </b>What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?<Br>\n",
    "<b>SOLUTION: </b>\n",
    "* MSE(MEAN SQUARED ERROR) : The MSE is calculated as the mean or average of the squared differences between predicted and expected target values in a dataset.\n",
    "\n",
    "MSE = 1 / N * sum for i to N (y_i – yhat_i)^2<Br>\n",
    "    \n",
    "    \n",
    "* MAE(MEAN ABSOLUTE ERROR) : it is calculated as the average of the absolute values of differences between the actual data points and predicted data points.\n",
    "    \n",
    "MAE = 1 / N * sum for i to N abs(y_i – yhat_i)   \n",
    "    \n",
    "* RMSE(ROOT MEAN SQUARED DEVIATION) : RMSE = sqrt(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d5755-22b1-47a4-8b52-f0123350a21d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10427f8b-7c0d-4d24-8f89-5ae38e4afd28",
   "metadata": {},
   "source": [
    "<b>QUESTION 5: </b>Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis.\n",
    "<Br>\n",
    "<b>SOLUTION: </b><Br>\n",
    "<b> MAE</b><br>\n",
    "ADVANTAGES: - the units are same as that of the dependent variable(output)\n",
    "            - robust to outliers\n",
    "\n",
    "DISADVANTAGES : - Optimization algorithms cannot be applied on this because the graph of absolute value function is not differentiable at origin.\n",
    "    \n",
    "<b>MSE</b>\n",
    "- ADVANTAGES : - Optimization algorithms can be applied on this because the graph of squared values  is  differentiable at origin.\n",
    "         \n",
    "\n",
    "- DISADVANTAGES : -  the units are not the same as that of the dependent variable(output)   \n",
    "                - it magnifies the error for outliers and therefore punishes the model for large errors.\n",
    "    \n",
    "<b>RMSE</b><br>\n",
    "ADVANTAGES : - the units are same as that of the dependent variable(output)\n",
    "     \n",
    "\n",
    "DISADVANTAGES : - it is sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad3cec-4a32-44ce-b5a8-ef1cfd96072b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a39e391-5acd-4e05-9e3c-b532be942ceb",
   "metadata": {},
   "source": [
    "<b>QUESTION 6: </b>Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?<Br>\n",
    "<b>SOLUTION: </b><Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfe55d-44f0-4fbd-8251-10a1a12bd403",
   "metadata": {},
   "source": [
    "* Lasso Regulariazation is a technique used in regression analysis to prevent overfitting of the model.\n",
    "* it works by adding a penalty term to the equation which shrinks the coefficients towards zero.\n",
    "* the amount of shrinkage is controlled by a tuning parameter called alpha, which is determined by cross validation.\n",
    "\n",
    "* Lasso and Ridge Regularization differ in terms of the penalty term added to the regression equation.\n",
    "* In Lasso, the penalty term is proportional to the absolute value of the coefficients whereas in Ridge, it is prorportional to the square of the coefficients.\n",
    "\n",
    "* Lasso generates sparse models where the values of some unnecessary coefficients is exactly zero, so it can be used for feature selection.\n",
    "* whereas, Ridge just shrinks the values of coefficients, so they are never exactly zero and it can't be used for feature selection.\n",
    "* This shows that Lasso can be used in dataset where we intend to identify and drop irrelevant or less relevant columns whereas Ridge is used where every feature is considered important for predicting the outcome and there is concern about multicollinearity among the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc8edd-4a59-4c15-aca5-4e2bb48654a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edba7aab-8708-48c8-a6eb-93f44406e197",
   "metadata": {},
   "source": [
    "<b>QUESTION 7: </b> How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate.\n",
    "<Br>\n",
    "<b>SOLUTION: </b><Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90d79d-430d-437a-ab41-c0cbe72cf725",
   "metadata": {},
   "source": [
    "* Regularization adds a penalty term to the cost function of the algorithm which effectively shrinks the values of coefficients towards zero. this helps in preventing overfitting.\n",
    "\n",
    "* Suppose we're trying to predict house prices based on location, number of bedrooms and square feets. our linear regression model fits the training data so well that it is overfitting. in such a scenario, it may perform very well on the training data but will perform poorly on new data.\n",
    "\n",
    "* we can use regularization to coerce it to find simpler solutions which may affect its performance on training data but it will eventually enhance its performance on new data. this helps in improving the model overall, especially in situations where the training data is limited or noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef075564-a2c6-47c1-af80-5f08fedaf4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32f967ba-cce4-4cdc-97ac-e1cbd05cd898",
   "metadata": {},
   "source": [
    "<b>QUESTION 8: </b>Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis.<Br>\n",
    "<b>SOLUTION: </b><Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2c45b-f56e-4fa2-a1d1-d026c6e74cc9",
   "metadata": {},
   "source": [
    "1. LIMITED INTERPRETABILITY: In regularization, the values of coefficients are shrunk to zero, this makes it challenging to determine the impact of individual predictors on the output. It is not advised to use regularization when we are trying ot understand the underlying relationship between predictors and output.\n",
    "\n",
    "2. LIMITED SCOPE: Regularization works well for linear models but may not work so well in case of more comples non-linear models\n",
    "\n",
    "3. OVER SIMPLICATION: Regularization shrinks the values of coefficients. it may happen that it shrinks the values so much that the model is now underfitting and doesn't capture the true patterns in the data.\n",
    "\n",
    "4. TUNING THE HYPERPARAMTERS: Regularization depends on hyperparameters like the strength of regularization. determining an accurate value for this is time consuming and requires domain expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072fcb3-683b-494c-be5a-dbce6da0426a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5f2c44b-6bf4-4e19-97fa-962e11f131b8",
   "metadata": {},
   "source": [
    "<b>QUESTION 9: </b>You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?<Br>\n",
    "<b>SOLUTION: </b><Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dba9fc-dfb7-47a8-8a5a-c6347c0fb3a0",
   "metadata": {},
   "source": [
    "* deciding which model is important depends on whether we are prioritizing accuracy or interpretability.\n",
    "*  if we are prioritizing accuracy, then B is better because it has a lower error than A.\n",
    "* if we are prioritizing interpretability , then A is better because the metric used is RMSE. RMSE penalizes large errors to a higher extent than MAE and so , in a situation where large errors should be avoided at all costs, RMSE is more appropriate. \n",
    "\n",
    "\n",
    "* One fo the limitations of using either metric alone is that it will only capture one aspect of the data and not the tradeoff between accuracy, interpretability and other metric considerations.\n",
    "* we should a variety of metrics and then weigh tne importance of  each of them as per the problem in hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60094347-e6dd-4a8b-89da-ac4233856b4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b83a8524-ae5d-4ef6-9690-2600b1289ec8",
   "metadata": {},
   "source": [
    "<b>QUESTION 10: </b>You are comparing the performance of two regularized linear models using different types of\n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "method?<br>\n",
    "<b>SOLUTION: </b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949536ad-14b7-4b75-809e-544b2552f2c4",
   "metadata": {},
   "source": [
    "* we can use performance metrics for each model to compare them. one might be good at reducing bias , the other might be good at reducing variance.\n",
    "*  we know that Lasso helps in feature selection but Ridge does not\n",
    "* so, if we know that our data needs feature selection as there are only few important columns, model B is a better choice, but if the data has multiple columns with small to medium effect sizes then , model A is a better choice.\n",
    "\n",
    "\n",
    "* There are limitations to choice of regularization method because Ridge can be less effective at feature selection whereas Lasso might be too agressive in eliminating features. We can Elastic Net Regression which is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34419cad-ee61-4fea-afc8-befa996f7f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
